# Supervised Fine-Tuning LLaMA2-13b-chat-hf on SST2

## Introduction

We demonstrate how to fine-tune the **LLaMA2-13b-chat-hf** model using QLoRA (Quantized LoRA) in this repository. We perform sentiment classification on the GLUE SST2 dataset and evaluate our fine-tuning performance.

HuggingFace Dataset [Link](https://huggingface.co/datasets/OneFly7/llama2-SST2-SFT-with-system-prompt/viewer/default/train?row=0)



## File

- **pre_processing.ipynb**: You can find the SST2 dataset preprocessing steps and the data upload process to HuggingFace in this notebook.
- **train.py**: You can find the SFT processes in this python file, which supports you train models by epoch or step.
- **evaluate.py**: You can find the model evaluation in this python file. The name of adapters_name is mandatory.

## Usage

```shell
# Train by epoch
python train.py --stop_condition epochs --epoch 50 --max_seq_length 256

# Train by step 
python train.py --stop_condition steps --steps 20 --max_seq_length 256

# Evaluate model
python evaluate.py --adapters_name Llama-2-13b-chat-hf-epoch1

```

**Attention:** There is an optional line on line 50 in train.py for selecting a small range of training data. For instance, if you would like to train model on 100 data for several epochs, you should re-add this line.

```python
# Add this line for multiple epoch on 100 examples
train_dataset = train_dataset.select(range(100))
```



## Data Pre-processing

### Prompt Template

```tex
<s>[INST] <<SYS>>
System prompt
<</SYS>>

User prompt [/INST] Model answer </s>
```

### Example on SST2

```tex
<s>[INST] <<SYS>>
You are a helpful, respectful and honest sentiment analysis assistant. And you are supposed to classify the sentiment of the sentence into one of the following categories: 'positive' or 'negative'.
<</SYS>>

Sentence: hide new secretions from the parental units 
Sentiment: [/INST] positive </s>

```

## Experiment

Training Dataset: SST2 Train Set

Validation Dataset: SST2 Validation Set (length of 872)

Max_seq_length = 256

Learning Rate = 2e-4

Default Epoch = 1

| Method              | # Training data | Accuracy | F1-score | Training Loss Variations | Irregular Output  |
| ------------------- | --------------- | -------- | -------- | ------------------------ | ----------------- |
| Fine-tuning (QLoRA) | 100 (1 epoch)   |          |          | 15.9→14.077              | All               |
| Fine-tuning (QLoRA) | 100 (10 epoch)  | 91.40%   | 0.92     | 15.9→0.0706              | Counter({'i': 3}) |
| Fine-tuning (QLoRA) | 100 (20 epoch)  | 93.58%   | 0.94     | 15.9→0.0015              |                   |
| Fine-tuning (QLoRA) | 100 (50 epoch)  | 94.50%   | 0.94     | 15.9→0.001               |                   |
| Fine-tuning (QLoRA) | 500             |          |          | 15.75→4.84               | All               |
| Fine-tuning (QLoRA) | 1000            | 91.97%   | 0.92     | 15.75→0.0958             | Counter({'i': 1}) |
| Fine-tuning (QLoRA) | 5000            | 95.41%   | 0.95     | 15.75→0.0839             |                   |
| Fine-tuning (QLoRA) | 10000           | 96.22%   | 0.96     | 15.75→0.043              |                   |
| Fine-tuning (QLoRA) | Full(60000+)    | 96.56%   | 0.97     | 15.75→0.051              |                   |

**P.S.** The "All" in the column "Irregular Output" means the output generated by model is still a complete answer sentence rather than expected output "positive" or "negative".



## Author

- Yifei Song (yifei.song@epfl.ch)
